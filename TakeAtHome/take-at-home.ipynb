{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfN3tns2OhOy"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/Jasonchen0317/CSGY-6613-Assignment/blob/main/TakeAtHome/take-at-home.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_1suaJROhO2"
      },
      "source": [
        "# Problem Set 1 (Take Home) - 40 points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCWsVSktOhO3"
      },
      "source": [
        "## PS 1.A - 20 points\n",
        "\n",
        "In [this video](https://www.youtube.com/watch?v=ho6JXE3EbZ8) the author explains how to extract various visualizations of what CNNs learn. [Your course site](https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/cnn/cnn-example-architectures/visualizing-what-convnets-learn.html) also covers the topic.\n",
        "\n",
        "Using the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), train a ResNet-50 based CNN on the classification task of $K=9$ classes (filter out the class `ship`) and create the following visualizations for first, middle and last blocks of ResNet-50. You are free to select a class to showcase such visualizations.\n",
        "\n",
        "* Visualizing intermediate convnet outputs (“intermediate activations”). This is useful to understand how successive convnet layers transform their input.\n",
        "\n",
        "* Visualizing convnets filters. This is useful to understand precisely what visual pattern or concept each filter in a convnet is receptive to.\n",
        "\n",
        "* Visualizing heatmaps of class activation in an image. This is useful to understand which part of an image where identified as belonging to a given class, and thus allows to localize objects in images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnCOGGhbOhO5",
        "outputId": "3f0b8a00-4c01-443c-b0c8-d21e0bd53a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-22 04:03:29.158783: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-10-22 04:03:29.604240: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-22 04:03:29.604286: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-22 04:03:29.606266: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-22 04:03:29.810090: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import Dense\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load cifar10 data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u_GR6fOO3RV",
        "outputId": "3269a336-013e-458e-b0ab-6df008eb35f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove ship class(label==8) & change label 9 to 8\n",
        "index = np.where(y_train.reshape(-1)==8)\n",
        "x_train, y_train = np.delete(x_train, index, 0), np.delete(y_train, index, 0)\n",
        "y_train[y_train==9]=8\n",
        "\n",
        "index = np.where(y_test.reshape(-1)==8)\n",
        "x_test, y_test = np.delete(x_test, index, 0), np.delete(y_test, index, 0)\n",
        "y_test[y_test==9]=8"
      ],
      "metadata": {
        "id": "e1V4bulFRzCK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values, counts = np.unique(y_train, return_counts=True)\n",
        "for value, count in zip(unique_values, counts):\n",
        "    print(f\"{value} occurs {count} times\")"
      ],
      "metadata": {
        "id": "tOF4JwkyeNmt",
        "outputId": "22ff6911-ab67-4939-9a5a-f3a340911379",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 occurs 5000 times\n",
            "1 occurs 5000 times\n",
            "2 occurs 5000 times\n",
            "3 occurs 5000 times\n",
            "4 occurs 5000 times\n",
            "5 occurs 5000 times\n",
            "6 occurs 5000 times\n",
            "7 occurs 5000 times\n",
            "8 occurs 5000 times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=9)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=9)"
      ],
      "metadata": {
        "id": "QCS1UB9NPDf0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (32, 32, 3)\n",
        "n_class = 9\n",
        "resnet_model = ResNet50(\n",
        "    input_shape=input_shape,\n",
        "    weights=None,\n",
        "    include_top=False\n",
        ")\n",
        "flattened = tf.keras.layers.Flatten()(resnet_model.output)\n",
        "fc1 = tf.keras.layers.Dense(128, activation='relu', name=\"AddedDense1\")(flattened)\n",
        "fc2 = tf.keras.layers.Dense(n_class, activation='softmax', name=\"AddedDense2\")(fc1)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=resnet_model.input, outputs=fc2)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "8kFtgNQgVpb2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "DnGE69rYsOYY",
        "outputId": "4a06df54-05c1-4237-b38f-b8990f3a518b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 38, 38, 3)            0         ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 16, 16, 64)           9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, 16, 16, 64)           256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, 16, 16, 64)           0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 18, 18, 64)           0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 8, 8, 64)             0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 8, 8, 64)             4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 8, 8, 64)             256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 8, 8, 64)             0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 8, 8, 64)             36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 8, 8, 64)             256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 8, 8, 64)             0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 8, 8, 256)            16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 8, 8, 256)            16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, 8, 8, 256)            0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, 8, 8, 256)            0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 8, 8, 64)             16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 8, 8, 64)             256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 8, 8, 64)             0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 8, 8, 64)             36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 8, 8, 64)             256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 8, 8, 64)             0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 8, 8, 256)            16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, 8, 8, 256)            0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, 8, 8, 256)            0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 8, 8, 64)             16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 8, 8, 64)             256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 8, 8, 64)             0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 8, 8, 64)             36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 8, 8, 64)             256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 8, 8, 64)             0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 8, 8, 256)            16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, 8, 8, 256)            0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, 8, 8, 256)            0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 4, 4, 128)            32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 4, 4, 128)            512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 4, 4, 128)            0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 4, 4, 128)            147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 4, 4, 128)            512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 4, 4, 128)            0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 4, 4, 512)            131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 4, 4, 512)            66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, 4, 4, 512)            0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, 4, 4, 512)            0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 4, 4, 128)            65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 4, 4, 128)            512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 4, 4, 128)            0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 4, 4, 128)            147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 4, 4, 128)            512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 4, 4, 128)            0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 4, 4, 512)            66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, 4, 4, 512)            0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, 4, 4, 512)            0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 4, 4, 128)            65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 4, 4, 128)            512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 4, 4, 128)            0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 4, 4, 128)            147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 4, 4, 128)            512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 4, 4, 128)            0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 4, 4, 512)            66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, 4, 4, 512)            0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, 4, 4, 512)            0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 4, 4, 128)            65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 4, 4, 128)            512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 4, 4, 128)            0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 4, 4, 128)            147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 4, 4, 128)            512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 4, 4, 128)            0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 4, 4, 512)            66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, 4, 4, 512)            0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, 4, 4, 512)            0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 2, 2, 256)            131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 2, 2, 256)            590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 2, 2, 1024)           525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 2, 2, 1024)           263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 2, 2, 1024)           4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, 2, 2, 1024)           4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, 2, 2, 1024)           0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, 2, 2, 1024)           0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 2, 2, 256)            262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 2, 2, 256)            590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 2, 2, 1024)           263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, 2, 2, 1024)           4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, 2, 2, 1024)           0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, 2, 2, 1024)           0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 2, 2, 256)            262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 2, 2, 256)            590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 2, 2, 1024)           263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, 2, 2, 1024)           4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, 2, 2, 1024)           0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, 2, 2, 1024)           0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 2, 2, 256)            262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 2, 2, 256)            590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 2, 2, 1024)           263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, 2, 2, 1024)           4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, 2, 2, 1024)           0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, 2, 2, 1024)           0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 2, 2, 256)            262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 2, 2, 256)            590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 2, 2, 1024)           263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, 2, 2, 1024)           4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, 2, 2, 1024)           0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, 2, 2, 1024)           0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 2, 2, 256)            262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 2, 2, 256)            590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 2, 2, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 2, 2, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 2, 2, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, 2, 2, 1024)           4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, 2, 2, 1024)           0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, 2, 2, 1024)           0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 1, 1, 512)            524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 1, 1, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 1, 1, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 1, 1, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 1, 1, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 1, 1, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 1, 1, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 1, 1, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, 1, 1, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, 1, 1, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, 1, 1, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, 1, 1, 2048)           0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 1, 1, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 1, 1, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 1, 1, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 1, 1, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 1, 1, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 1, 1, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 1, 1, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, 1, 1, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, 1, 1, 2048)           0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, 1, 1, 2048)           0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 1, 1, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 1, 1, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 1, 1, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 1, 1, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 1, 1, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 1, 1, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 1, 1, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, 1, 1, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, 1, 1, 2048)           0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, 1, 1, 2048)           0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
            "                                                                                                  \n",
            " AddedDense1 (Dense)         (None, 128)                  262272    ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " AddedDense2 (Dense)         (None, 9)                    1161      ['AddedDense1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23851145 (90.98 MB)\n",
            "Trainable params: 23798025 (90.78 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "L8XMRSRIbgHq",
        "outputId": "b83484c1-e2b1-4064-9231-713b07249f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1407/1407 [==============================] - 135s 71ms/step - loss: 1.6911 - accuracy: 0.3773 - val_loss: 1.6327 - val_accuracy: 0.4219\n",
            "Epoch 2/50\n",
            "1407/1407 [==============================] - 92s 66ms/step - loss: 1.4518 - accuracy: 0.4707 - val_loss: 1.7269 - val_accuracy: 0.4037\n",
            "Epoch 3/50\n",
            "1407/1407 [==============================] - 97s 69ms/step - loss: 1.3837 - accuracy: 0.4917 - val_loss: 1.6270 - val_accuracy: 0.4092\n",
            "Epoch 4/50\n",
            "1407/1407 [==============================] - 89s 63ms/step - loss: 1.2914 - accuracy: 0.5319 - val_loss: 1.6823 - val_accuracy: 0.4582\n",
            "Epoch 5/50\n",
            "1407/1407 [==============================] - 92s 65ms/step - loss: 1.0668 - accuracy: 0.6206 - val_loss: 1.9209 - val_accuracy: 0.4040\n",
            "Epoch 6/50\n",
            "1407/1407 [==============================] - 91s 64ms/step - loss: 0.9579 - accuracy: 0.6629 - val_loss: 1.1025 - val_accuracy: 0.6128\n",
            "Epoch 7/50\n",
            "1407/1407 [==============================] - 94s 67ms/step - loss: 0.8589 - accuracy: 0.7029 - val_loss: 1.3348 - val_accuracy: 0.5466\n",
            "Epoch 8/50\n",
            "1407/1407 [==============================] - 94s 67ms/step - loss: 0.7807 - accuracy: 0.7320 - val_loss: 1.5117 - val_accuracy: 0.5563\n",
            "Epoch 9/50\n",
            "1407/1407 [==============================] - 91s 64ms/step - loss: 0.7014 - accuracy: 0.7587 - val_loss: 0.8913 - val_accuracy: 0.7111\n",
            "Epoch 10/50\n",
            "1407/1407 [==============================] - 93s 66ms/step - loss: 0.6307 - accuracy: 0.7820 - val_loss: 0.8308 - val_accuracy: 0.7271\n",
            "Epoch 11/50\n",
            "1407/1407 [==============================] - 94s 67ms/step - loss: 0.5510 - accuracy: 0.8100 - val_loss: 1.0101 - val_accuracy: 0.6862\n",
            "Epoch 12/50\n",
            "1407/1407 [==============================] - 92s 65ms/step - loss: 0.5064 - accuracy: 0.8268 - val_loss: 0.9825 - val_accuracy: 0.6829\n",
            "Epoch 13/50\n",
            "1407/1407 [==============================] - 91s 65ms/step - loss: 0.4301 - accuracy: 0.8534 - val_loss: 0.8578 - val_accuracy: 0.7304\n",
            "Epoch 14/50\n",
            "1407/1407 [==============================] - 89s 63ms/step - loss: 0.3654 - accuracy: 0.8752 - val_loss: 0.8179 - val_accuracy: 0.7449\n",
            "Epoch 15/50\n",
            "1407/1407 [==============================] - 83s 59ms/step - loss: 0.3053 - accuracy: 0.8954 - val_loss: 0.9286 - val_accuracy: 0.7226\n",
            "Epoch 16/50\n",
            "1407/1407 [==============================] - 89s 63ms/step - loss: 0.2916 - accuracy: 0.8999 - val_loss: 0.9945 - val_accuracy: 0.7269\n",
            "Epoch 17/50\n",
            "1407/1407 [==============================] - 86s 61ms/step - loss: 0.2381 - accuracy: 0.9196 - val_loss: 1.0643 - val_accuracy: 0.7063\n",
            "Epoch 18/50\n",
            "1407/1407 [==============================] - 92s 66ms/step - loss: 0.1989 - accuracy: 0.9322 - val_loss: 0.9881 - val_accuracy: 0.7363\n",
            "Epoch 19/50\n",
            "1407/1407 [==============================] - 93s 66ms/step - loss: 0.1854 - accuracy: 0.9373 - val_loss: 1.0743 - val_accuracy: 0.7307\n",
            "Epoch 20/50\n",
            "1407/1407 [==============================] - 91s 64ms/step - loss: 0.1628 - accuracy: 0.9452 - val_loss: 1.1742 - val_accuracy: 0.7097\n",
            "Epoch 21/50\n",
            "1407/1407 [==============================] - 94s 67ms/step - loss: 0.1487 - accuracy: 0.9494 - val_loss: 1.0157 - val_accuracy: 0.7434\n",
            "Epoch 22/50\n",
            "1407/1407 [==============================] - 89s 63ms/step - loss: 0.1327 - accuracy: 0.9546 - val_loss: 1.4338 - val_accuracy: 0.7144\n",
            "Epoch 23/50\n",
            " 440/1407 [========>.....................] - ETA: 1:00 - loss: 0.1202 - accuracy: 0.9615"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def"
      ],
      "metadata": {
        "id": "JUa-8f3fsM9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = model.layers\n",
        "filters, biases = model.layers[2].get_weights()\n",
        "print(layer[2].name, filters.shape)"
      ],
      "metadata": {
        "id": "03_0Cq2er76c",
        "outputId": "dd6926cf-4c32-4914-f619-b5d85d5c0ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1_conv (7, 7, 3, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig1=plt.figure(figsize=(8, 12))\n",
        "columns = 8\n",
        "rows = 8\n",
        "n_filters = columns * rows\n",
        "for i in range(1, n_filters +1):\n",
        "    f = filters[:, :, :, i-1]\n",
        "    fig1 =plt.subplot(rows, columns, i)\n",
        "    fig1.set_xticks([])  #Turn off axis\n",
        "    fig1.set_yticks([])\n",
        "    plt.imshow(f[:, :, 0], cmap='gray') #Show only the filters from 0th channel (R)\n",
        "    #ix += 1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dcxMqS_xtjnu",
        "outputId": "b9c60eee-5aea-4737-9570-ac7bc42481da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x1200 with 64 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.keras\")"
      ],
      "metadata": {
        "id": "zYomxPrrkogf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM7_FWrvOhO7"
      },
      "source": [
        "## PS 1.B - 20 points\n",
        "\n",
        "In [this notebook](https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/transfer-learning/transfer_learning_tutorial.html) we showcase _transfer learning_ using a pre-trained CNN model.\n",
        "\n",
        "Perform the fine-tunning and feature extraction methods of transfer learning using the same model as in PS-1A, for the class `ship`.\n",
        "\n",
        "Repeat the visualization of PS-1.A before and after  transfer learning and write a conclusive summary as to the relative value of the two methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5GhEcHHOhO8"
      },
      "outputs": [],
      "source": [
        "# Insert your code here"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}